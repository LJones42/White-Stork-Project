---
title: "WSP setup and cleaning code"
author: "Lizzie Jones^[University of Brighton, l.jones4@brighton.ac.uk]"
date: "02/05/2021"
output:
  pdf_document:
    number_sections: no
  html_document:
    number_sections: no
  word_document: default
---


## WSP Data cleaning


#### About this rMarkdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>. To generate the document of all content, click the **Knit** button. 

This rMarkdown document will be periodically updated and uploaded to the OneDrive folder and pushed to the WSP GitHub code repository. The primary format of this document is HTML, but this can be easily changed by changing the output (e.g. PDF, GitHub) using the 'output' section at the top of the document. The possible output formats are listed here: https://rmarkdown.rstudio.com/lesson-9.html.

```{r setup/packages, include=FALSE, warning=FALSE}
# This code assumes that all packages are installed. If not, use 'install.packages' e.g. install.packages("likert")
# install.packages("hms")
# Key packages for data wrangling
wrangling <- c("dplyr","tidyverse","purr","magrittr","lubridate","hms",
             "data.table","plyr","tidyr","tibble","reshape2")
lapply(wrangling, require, character.only = TRUE) 
# Useful survey analysis packages
survey <- c("likert","careless")
lapply(survey, require, character.only = TRUE) 
# Useful packages for statistics
stats <- c("stats","ggpubr","lme4","MASS","car","psych",
                   "MuMIn","glmmTMB","nlme","DHARMa")
lapply(stats, require, character.only = TRUE) 
# Useful packages for text analysis
# text <- c("tm","tau","koRpus","lexicon","sylly","textir",
#          "textmineR","MediaNews", "lsa","SemNeT","ngram","ngramrr",
#          "corpustools","udpipe","textstem", "tidytext","text2vec")
# lapply(text, require, character.only = TRUE) 
# Favourite data visualisation packages
vismap <- c("ggvis","htmlwidgets","maps", "lattice","ggmap","ggplot2","plotly","rnaturalearth",
            "RColorBrewer", "sjPlot", "ggrepel", "rgdal", "maptools", "gpclib")
lapply(vismap, require, character.only = TRUE) 
gpclibPermit()  # Gives maptool permission to use gpclib
```

```{r working directories and data upload, include=FALSE}
# Load in working  directory and datasets
setwd("~/Documents/White-Stork-Project")
# Load in the data
original_data <- read.csv("Stork_MainDataset.csv", header = TRUE, stringsAsFactors=TRUE)
all_data <- read.csv("Stork_Dataset_Radapted.csv", header = TRUE, stringsAsFactors=TRUE)
# I have created a new column called 'UniqueID_all' to allow me to remove inidividual participants 
nrow(all_data)
```

```{r column groups, include=FALSE}

### Grouping columns
# Grouping Likert scale question columns by selecting Question numbers (and dropping scores or open questions)
overall_score_colnames <- select(all_data, ends_with("overallscore"))

Q4_knowledge_colnames <- select(all_data, starts_with("Q4"), -ends_with('score'))
Q5_diet_colnames <- select(all_data, starts_with("Q5"))
Q6_habitat_colnames <- select(all_data, starts_with("Q6"))
Q8_nesting_colnames <- select(all_data, ends_with("nesting"))
Q8_seen_colnames <- select(all_data, starts_with("Q8_"))

# Source of information (current and preferred)
Q10_cursource_colnames <- select(all_data, starts_with("Q10a"))
Q10_prefsource_colnames <- select(all_data, starts_with("Q10b"))

# Q12-14 = attitudes to white storks
all_attitude_colnames <- select(all_data, starts_with("Q13"), starts_with("Q13"), starts_with("Q14"), -ends_with('score'))
Q12_attitude_colnames <- select(all_data, starts_with("Q12"), -ends_with('score'))
Q13_attitude_colnames <- select(all_data, starts_with("Q13"), -ends_with('score'))
Q14_attitude_colnames <- select(all_data, starts_with("Q14"), -ends_with('score'))

## Q15 = WSP support
## Q16 = Views on current management
Q17_management_colnames <- select(all_data, starts_with("Q17"), -ends_with('open'))
Q18_exp_colnames <- select(all_data, starts_with("Q18_"), -ends_with('open')) # Frequency of
Q19_NCI_colnames <- select(all_data, starts_with("Q19"), -ends_with('score')) # Q19 total score = NCI
Q20_envconcern_colnames <- select(all_data, starts_with("Q20"), -ends_with('score')) # Q21 total score = Env.concern score
Q21_ProCoBS_colnames <- select(all_data, starts_with("Q21"), -ends_with('score')) # Q21 total score = ProCoBS
Q23_BIS_colnames <- select(all_data, starts_with("Q23"), -ends_with('score')) # Q23 total score = BirdInterestScore
```




### Data cleaning walk-through

This rMarkdown document has been written to take the reader through the data cleaning process for the White Stork Survey dataset. 

The key aims of this rMarkdown are as follows:

1. View the data and familiarise the reader with the overall dataset
2. Format any data/questions into the appropritae format (e.g. factors or numerical responses)
3. Convert any raw data into more useable fomrats (e.g. seconds, rather than sec/min/hr)
4. Check for straightlining, even-odd consistencies and non-serious responses and consider for removal
5. Check open-ended questions and remove any non-serious/joke responses
6. Check for internal consistency of scores using Cronbach's Alpha


#### Initial formatting

To easily view which respondents had seen white Storks inside or outside the UK, and I have created a new composite value column with which we can sort or subset respondents (column = "Q8.WhereSeen, values = UK, Outside UK, Both, Neither, NA)

I have created a new age column to create matching age groups for both surveys (new column = 'Age_group_match'). The oldest age group for both surveys is now 65+.
I converted the 'TimeTaken' column to a total number of seconds (SecsTaken) for easier to more easily investigate means and quantiles. 


```{r data formatting main dataset}
# Cleaning full dataset to prevent having to do code for all samples


## Create a composite columns of where respondents had seen White Storks (UK, Outside UK, or Both)
# Multiple conditions when adding new column to dataframe:
str(all_data$Q8.1_UK) # Column is integer so need to format case_when accordingly
all_data <- all_data %>% mutate(Q8.WhereSeen =
                     case_when(Q8.1_UK == 1L & Q8.1_OutsideUK == 0L ~ "UK", 
                               Q8.1_UK == 1L & Q8.1_OutsideUK == NA_integer_ ~ "UK",
                               Q8.1_UK == 0L & Q8.1_OutsideUK == 1L ~ "OutsideUK",
                               Q8.1_UK == NA_integer_ & Q8.1_OutsideUK == 1L ~ "OutsideUK",
                               Q8.1_UK == 1L & Q8.1_OutsideUK == 1L ~ "Both",
                               Q8.1_UK == 0L & Q8.1_OutsideUK == 0L ~ "Neither",
                               Q8.1_UK == NA_integer_ & Q8.1_OutsideUK == NA_integer_ ~ "NA",))
# Move new column next to existing Q8 columns and view new column
all_data <- all_data %>%  sjmisc::move_columns(Q8.WhereSeen, .after = "Q8.1_OutsideUK")


## Age columns
all_data$Age_group_match <- all_data$Age_group # Create new column with matching age-group formats
all_data <- all_data  %>%
  dplyr::mutate(Age_group_match = recode(Age_group_match, "c('65-74', '75 and over')='65+'"))
summary(all_data$Age_group_match)

## Formatting date and time columns
# Create numeric column of time taken (seconds)
all_data$SecsTaken <- as.numeric(lubridate::seconds(all_data$TimeTaken)) 
all_data$StartDate <- as.Date(all_data$StartDate, format = "%d/%m/%Y")
all_data$CompletionDate <- as.Date(all_data$CompletionDate, format = "%d/%m/%Y")


```

After the WSP group meeting on 17/05/21 I removed the 3 Northern Irish respondents from the Proactive sample and merged the respondents thta selected Wadhurst and Wadhurst Park as the nearest release site.

```{r respondent merging or removal}

### Removing the N.Ireland respondents
summary(all_data$Region)
# Remove rows where Region = "Northern Ireland"
all_data <- subset(all_data, all_data$Region != "Northern Ireland") 
 # Drop the N.Ireland factor level
all_data$Region <- droplevels(all_data$Region)
summary(all_data$Region)

### Merging the Wadhurst and Wadhurst Park respondents
all_data <- transform(all_data,
          ReleaseSite=plyr::revalue(ReleaseSite,c("Wadhurst"="Wadhurst Park")))
summary(all_data$ReleaseSite)


```

\newpage

#### Full dataset checks

I initially went through the full dataset manually and checked for any respondents that were clearly straightlining and/or not taking the questionnaire seriously (e.g. open answers such as "jkjkjkjk"). I removed the entire row for respondents that were both non-serious and straightlining, but I removed the open answers only for those who appreared to take the close questions seriously and put junk answers for the open questions.


```{r straightlining, warning=FALSE, messages=FALSE}

##### Data cleaning using the 'careless' package

# Overall straightlining (whole survey)
 # Identifies the longest string of identical consecutive responses for each observation
all_straightline <- longstring(all_data, avg = FALSE)
summary(all_straightline) # Mean number of consecutive attitude answers = 14, max = 14
 # 127 rows with 14 consecutive answers (possible candidates for removal)
all_possible_st <- which(grepl(14, all_straightline))


### Checking straightlining for all Likert style questions with over 3 columns
# Checking the attitudes to WS columns (Q12, 13 and 14)
ncol(all_attitude_colnames) # Max possible number of consecutive answers is 10
# Identifies the longest string of identical consecutive
attitudes_straight <- longstring(all_attitude_colnames, avg = FALSE)
summary(attitudes_straight) # Mean number of consecutive attitude answers = 3
# Find rows with 10 consecutive answers (possible candidates for removal)
attitude_possible_st <- which(grepl(10, attitudes_straight)) 

# Checking the NCI columns
ncol(Q19_NCI_colnames) # Max possible number of consecutive answers is 6
nci_straight <- longstring(Q19_NCI_colnames, avg = FALSE) 
summary(nci_straight) # Mean number of consecutive attitude answers = 3
# Find rows with 6 consecutive answers (~1700 gave max consecutive for NCI
# across both surveys, which makes sense especially for proactive sample, 
# as sample will have a high interest and connection to nature)
# Therefore will not remove suspected participants based on this question
nci_possible_st <-which(grepl(6, nci_straight))

# Checking the ProCoBS columns
ncol(Q21_ProCoBS_colnames) # Max possible number of consecutive answers is 4
ProCoBS_straight <- longstring(Q21_ProCoBS_colnames, avg = FALSE)
summary(ProCoBS_straight) # Mean number of consecutive attitude answers = 3
# 245 rows with 10 consecutive answers (possible candidates for removal,
# but only 4 questions so unintentional straightlining would be likely for this question)
# Therefore will not remove suspected participants based on this question
pro_possible_st <-which(grepl(4, ProCoBS_straight))



# Comparing overall suspected straightlining row numbers to suspected straightlining attitude row numbers
both_straightline_rownames <- intersect(all_possible_st, attitude_possible_st) # rows in both
both_straightline_rownames
rows_straightlined <- all_data[c(2600, 2908, 3035, 3203, 3519), ] # Create df to view
summary(rows_straightlined$SecsTaken) # Mean survey time = 235 seconds or ~4 mins. 
# Most have skipped the open questions

# Removing straightlined participants
row_straightlined <- c(2600, 2908, 3035, 3203, 3519) # 5 respondents
## Create new dataset for further analysis and remove rows with straightlining etc.
data_clean <- all_data[!all_data$UniqueID_all %in% row_straightlined,]

# Writing this new dataframe of the cleaned dataframe as a dataframe for visual inspection in Excel
write.csv(data_clean, "WSP_R_cleaned_dataset.csv")  ### Once cleaned save as WSP_R_cleaned_dataset1.csv

```



\newpage

#### Checking the fastest responses

I then focussed on the fastest 5% of respondents across both surveys as they are most likely to have straightlined through the survey. I visually inspected the data, then used the 'careless' package to find evidence of straightlining 'even-odd' consistencies, and intra-individual response variability (IRV), across the whole survey and within the multiple choice questions (particularly questions 4, 5, 13, 15, 16, 17, 22, 23, 24).

```{r data time-checks}

### Explore average time taken to complete questionnaire and check for straightlining
quantile(data_clean$SecsTaken, 0.1) # Fastest 10% of all respondents = completion in 188.9 seconds/ about 3 mins
quantile(data_clean$SecsTaken, 0.05) # Fastest 5% of all respondents = completion in 117.95 seconds/ about 2 mins
quantile(data_clean$SecsTaken, 0.025) # Fastest 2.5% of all respondents = completion in 70.975 seconds/ about 1.2 mins
fastest_10 <- subset(data_clean, SecsTaken < 191) # Sample of fastest 10% of all respondents
fastest_5 <- subset(data_clean, SecsTaken < 121) # Sample of fastest 5% of all respondents
fastest_2.5 <- subset(data_clean, SecsTaken < 72) # Sample of fastest 2.5% of all respondents
summary(fastest_5$SurveyType) # 96% of respondents in fastest 5% are from the NatRep sample
summary(fastest_2.5$SurveyType) # 100% of respondents in fastest 2.5% are from the NatRep sample
```

\newpage

### Focussing on the the fastest 5% of responses

Here I have checked the responses of the fastest 5% of the dataframe (after straightlined responses had been removed). I compare the mean values of the numeric/score columns between the full cleaned dataset and the fastest 5% but as there don't seem to be significant differences between the full dataset and the fastest 5% sample, I manually checked the full dataset.

```{r data checks fastest 5, warning=FALSE, messages=FALSE}

### Checking the fastest 5% of respondents for straightlining across whole survey 
 # Identifies the longest string of identical consecutive responses for each respondent
long_fastest_5 <- longstring(fastest_5, avg = FALSE)
evenodd_fastest_5 <- evenodd(fastest_5, rep(5,10))

# Checking the fastest 5% for straightlining within each set of mutliple choice questions
# summary(data_clean$Q5_overallscore_diet) # e.g. Q5 diet
# summary(fastest_5$Q5_overallscore_diet) ### Not a significant difference in Q5 diet score
  
### Full cleaned dataset
careless_all <- evenodd(data_clean, rep(5,10))
# Calculates the intra-individual response variability (IRV)
irv_total <- irv(data_clean)

### Fastest 5%
careless_fast <- evenodd(fastest_5, rep(5,10))
irv_fast <- irv(fastest_5)

# Writing the fastest 5% subset of the cleaned dataframe as a dataframe for visual inspection in Excel
write.csv(fastest_5, "WSP_fastest5.csv") 

```

### Creating a final, cleaned dataset

The full dataset was checked for overall straightlining again and then manually checked the dataset for any irregularities and non-serious answers. Many respondents who wrote non-serious/joke answers in the open questions also shows evidence of straighlining, therefore these respondents were removed. If the respondent did not appreat to straightline, but had written random letters (e.g. "jadbfsjdbg") in the open questions, only the open question answers were removed.

One cleaned I wrote a new 'final' dataset as a CSV file for further  stats and analysis called 'final_data'.

```{r checking non-serious respondents, warning=FALSE, messages=FALSE}

##### Manually check the full dataset 
# (write down UniqueID_all numbers for removal in R)
# Manually remove non-serious open-ended question responses
# ---------------------------------------------------------------------

# Load in manually cleaned dataset
data_clean1 <- read.csv("WSP_R_cleaned_dataset1.csv", header = TRUE, stringsAsFactors=TRUE)

# Removed as comments suggested not taking the survey seriously (e.g. UniqueID_all = 3309) 
# Or straightlining that hasn't picked up in previous analysis
manualcheckID_to_remove <- c(566, 916, 2608, 2643, 2738, 2746, 2758, 2777, 2869, 2889, 3022,
                            3201, 3209, 3308, 3309, 3321, 3352,3363, 3441, 3464, 3466) 

## Create new dataset for further analysis and remove rows with straightlining etc.
data_clean2 <- data_clean1[!data_clean1$UniqueID_all %in% manualcheckID_to_remove,]


#### Checking timeline of respondent removal
nrow(original_data) # 3560 - Original dataset sample size
nrow(all_data) ### 3557 - After removal of the 3 N.Ireland respondents
nrow(data_clean) # 3552 - After removal of 5 straightlined respondents
nrow(data_clean2) # 3531


```

```{r final dataframes, echo = FALSE}

# View and save the FINAL cleaned dataframe as a CSV file for use in other r scripts
str(data_clean2)
write.csv(data_clean2, "WSP_R_cleaned_dataset_Final.csv")

# ----------------------------------------------------------

# Load in manually cleaned dataset
final_data <- read.csv("WSP_R_cleaned_dataset_Final.csv", header = TRUE, stringsAsFactors=TRUE)

# Comparing datasets
nrow(original_data)
summary(original_data$SurveyType)
nrow(final_data) # 29 participants have been removed 5 from the Proactive sample and 24 from the Nat.Rep sample
summary(final_data$SurveyType)
```


\newpage

### Cronbach's alpha

Now we have a cleaned dataset I have gone through the grouped columns are numeric scores of Likert or multiple choice questions, including: AttitudeScore, NCI, EnvConcern.score, ProCoBS and BirdInterestScore.

Based on the 0.7 threshold, all groups have an acceptable Cronbach's alpha score.


```{r cronbachs alpha, warning=FALSE, message=FALSE}

### Reminding myself of the column names again!
# colnames(final_data)
library("psych")

# Using Cronbach's alpha on the score columns using the psych package (alpha::psych)
# Questions 13 & 14 attitudes
final_data %>%
  select(., starts_with("Q12"), starts_with("Q13"), starts_with("Q14")) %>%
  select(., ends_with('score')) %>%
  psych::alpha(title = "Attitudes")

# Question 21 ProCoBS
final_data %>%
  select(., starts_with("Q21") & ends_with('score')) %>%
  psych::alpha(title = "ProCoBS")

# Question 22 BirdInterestScore
final_data %>%
  select(., starts_with("Q23") & ends_with('Score')) %>%
  psych::alpha(title = "BirdInterestScore")

```


---
title: "WSP setup and demographics code"
author: "Lizzie Jones^[University of Brighton, l.jones4@brighton.ac.uk]"
date: "02/05/2021"
output:
  html_document:
    number_sections: no
  pdf_document:
    number_sections: no
  word_document: default
---


## WSP - Demographics exploration, analysis and visualisations

#### About this rMarkdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>. To generate the document of all content, click the **Knit** button. 

This rMarkdown document will be periodically updated and uploaded to the OneDrive folder and pushed to the WSP GitHub code repository. The primary format of this document is HTML, but this can be easily changed by changing the output (e.g. PDF, GitHub) using the 'output' section at the top of the document. The possible output formats are listed here: https://rmarkdown.rstudio.com/lesson-9.html.

```{r setup/packages, include=FALSE}
# This code assumes that all packages are installed. If not, use 'install.packages' e.g. install.packages("likert")
# install.packages("hms")

# Key packages for data wrangling
wrangling <- c("dplyr","tidyverse","purr","magrittr","lubridate","hms",
             "data.table","plyr","tidyr","tibble","reshape2")
lapply(wrangling, require, character.only = TRUE) 

# Useful survey analysis packages
survey <- c("likert","careless")
lapply(survey, require, character.only = TRUE) 

# Useful packages for statistics
stats <- c("stats","ggpubr","lme4","MASS","car","psych",
                   "MuMIn","glmmTMB","nlme","DHARMa")
lapply(stats, require, character.only = TRUE) 

# Useful packages for text analysis
# text <- c("tm","tau","koRpus","lexicon","sylly","textir",
#          "textmineR","MediaNews", "lsa","SemNeT","ngram","ngramrr",
#          "corpustools","udpipe","textstem", "tidytext","text2vec")
# lapply(text, require, character.only = TRUE) 

# Favourite data visualisation packages
vismap <- c("ggvis","htmlwidgets","maps", "lattice","ggmap","ggplot2","plotly","rnaturalearth",
            "RColorBrewer", "sjPlot", "ggrepel", "rgdal", "maptools", "gpclib", "rcartocolor", "leaflet")
lapply(vismap, require, character.only = TRUE) 
gpclibPermit()  # Gives maptool permission to use gpclib

# Creating a colourblind-friendly 'safe' palette
safe_colorblind_palette <- c("#88CCEE", "#CC6677", "#DDCC77", "#117733", "#332288", "#AA4499", 
                             "#44AA99", "#999933", "#882255", "#661100", "#6699CC", "#888888")
scales::show_col(safe_colorblind_palette)

```

```{r working directories and data upload, include=FALSE}
# Load in working  directory and datasets
setwd("~/Documents/White-Stork-Project")
# Load in the data
original_data <- read.csv("Stork_MainDataset.csv", header = TRUE, stringsAsFactors=TRUE)
all_data <- read.csv("Stork_Dataset_Radapted.csv", header = TRUE, stringsAsFactors=TRUE)

# Load in cleaned dataset
final_data <- read.csv("WSP_R_cleaned_dataset_Final.csv", header = TRUE, stringsAsFactors=TRUE)

# Create new  group columns for graph/tables
# PROXIMITY to any WS release site
final_data <- mutate(final_data, SiteProximity =
                       ifelse(ReleaseSite == "No", "Not local", "Local"))
## GENDER
# Collapse levels of Gender that have very low sample size to N/A
levels(final_data$Gender)[levels(final_data$Gender)%in%c("Prefer not to answer","Prefer to self-describe")] <- "N/A"

## AGE
# Age recode groups.
young = c("18-24", "25-34", "35-44")
mid = c("45-54", "55-64")
older = c("65+")
# add another column.
final_data$Age_short <- ifelse(final_data$Age_group_match %in% young, "18-44", 
                        ifelse(final_data$Age_group_match %in% mid, "45-64",
                              ifelse(final_data$Age_group_match %in% older, "65+", "N/A")))
## EDUCATION
# Recode groups.
degree = c("Postgraduate degree (Masters; Doctorate)", "Undergraduate degree")
high = c( "Secondary school (GCSEs, A Levels or equivalent)", "Further Education")
noformal = c("No formal qualifications")
# add another column.
final_data$Education_short <- ifelse(final_data$Education %in% degree, "University graduate", 
                              ifelse(final_data$Education %in% high, "High school/College",
                              ifelse(final_data$Education %in% noformal, "No formal quals.", "Other")))
## OCCUPATION
# View others
levels(final_data$Occupation_other)
# Recode groups.
unemployed = c("Unemployed", "Retired")
education = c("Education")
environmental = c( "Environment, Nature & Wildlife", "Farming & Agriculture", "Horticulture/Gardening/Landscaping",
                   "Fisheries & Aquaculture")
student = c("Student")
prefer_not = c("Prefer not to answer")
other = c("Other")
# add another column and define factor levels
final_data$Occupation_short <- ifelse(final_data$Occupation %in% unemployed, "Unemployed/Retired", 
                              ifelse(final_data$Occupation  %in% education, "Education",
                              ifelse(final_data$Occupation  %in% environmental, "Environment/Nature",
                              ifelse(final_data$Occupation %in% student, "Student", 
                              ifelse(final_data$Occupation  %in% prefer_not, "Prefer not to say",
                              ifelse(final_data$Occupation  %in% other, "Other","Non-environmental"))))))


### Create two dataframes: one for each data collection (Proactive survey and Nationally representative survey) for easier comparison
proact_data <- final_data[which(final_data$SurveyType == "Proactive"),]
natrep_data <- final_data[which(final_data$SurveyType == "NatRep"),]

```

## Exploring respondent demographics

The distribution of gender and education is explored and compared between samples using stacked bar plots.

```{r demographics, echo=FALSE, warning=FALSE, message=FALSE}

# Create seperate dataframe for all demographics
demo_columns <- c("SurveyType", "Age_group_match","Age_short", "Gender", "Education", "Education_short",
                                "Occupation", "Occupation_short", "Region", "Area_type", "Postcode", "ReleaseSite", "SiteProximity")
# Create seperate dataframe for All data, Nationally representative and Proactive demographics
all_demo <- final_data %>% select(demo_columns)
natrep_demo <- natrep_data %>% select(demo_columns)
proact_demo <- proact_data %>% select(demo_columns)
## Age
# Stacked barplot of gender per survey
all_age_df<- all_demo  %>%
  group_by(SurveyType, Age_short) %>%
  summarise(counts = n()) %>%
  mutate(Percentage = round(counts/sum(counts)*100, 2))
age_bar <- ggplot(all_age_df, aes(x = SurveyType, y = Percentage, fill = Age_short)) +
  geom_col(position = position_stack(reverse = TRUE)) +
  geom_text(aes(label = paste0(Percentage, "%")),
            position = position_stack(vjust = 0.5, reverse = TRUE)) +
  scale_fill_brewer(palette = "Pastel1") +
  theme_minimal(base_size = 12) + xlab("Sample")+ labs(fill = "Age group", x = "Sample") 
## Gender
# Stacked barplot of gender per survey
all_gender_df<- all_demo  %>%
  group_by(SurveyType, Gender) %>%
  summarise(counts = n()) %>%
  mutate(Percentage = round(counts/sum(counts)*100, 2))
gender_bar <- ggplot(all_gender_df, aes(x = SurveyType, y = Percentage, fill = Gender)) +
  geom_col(position = position_stack(reverse = TRUE)) +
  geom_text(aes(label = paste0(Percentage, "%")),
            position = position_stack(vjust = 0.5, reverse = TRUE)) +
  scale_fill_brewer(palette = "Pastel1") +
  theme_minimal(base_size = 12) + xlab("Sample")
## Education
# Stacked barplot of gender per survey
all_education_df <- all_demo  %>%
  group_by(SurveyType, Education_short) %>%
  summarise(counts = n()) %>%
  mutate(Percentage = round(counts/sum(counts)*100, 2))
all_education_df$Education_short <- ordered(all_education_df$Education_short, 
            levels = c("University graduate","High school/College","No formal quals.","Other"))
education_bar <- ggplot(all_education_df, aes(x = SurveyType, y = Percentage,
         fill = factor(Education_short))) +
  geom_col(position = position_stack(reverse = TRUE)) +
  geom_text(aes(label = paste0(Percentage, "%")),
            position = position_stack(vjust = 0.5, reverse = TRUE)) + # geom_text_repel
  scale_fill_brewer(palette = "Pastel1") + labs(fill = "Education group", x = "Sample") +
  theme_minimal(base_size = 12)

## Occupation
# Create percentages
all_occupation_df <- all_demo  %>%
  group_by(SurveyType, Occupation_short) %>%
  summarise(counts = n()) %>%
  mutate(Percentage = round(counts/sum(counts)*100, 2))
all_occupation_df$Occupation_short <- ordered(all_occupation_df$Occupation_short, levels = c("Non-environmental","Environment/Nature",
               "Unemployed/Retired","Education","Student","Other","Prefer not to say"))
occupation_bar <- ggplot(all_occupation_df, aes(x = SurveyType, y = Percentage,
         fill = factor(Occupation_short))) +
  geom_col(position = position_stack(reverse = TRUE)) +
  geom_text(aes(label = paste0(Percentage, "%")),
            position = position_stack(vjust = 0.5, reverse = TRUE)) + # geom_text_repel
  scale_fill_brewer(palette = "Pastel1") + labs(fill = "Occupation group", x = "Sample") +
  theme_minimal(base_size = 12)
```

```{r demographics - stacked plots, echo=FALSE, message=FALSE, warning=FALSE}
age_bar
gender_bar
education_bar
occupation_bar
```


\newpage


### Respondent demographics tables

The table below (created using the package "table1") outlines the demographic characteriscs of each of the two samples, and the overall demographics of all respondents across both samples. For each demographic variable the tables provides a breakdown of the number of respondents within each level/group and the percentage.


```{r SHORT demographics table, echo=FALSE, message=FALSE, warning=FALSE}
# Demographics table for publication

library("table1")
short_demo <- as.data.frame(all_demo)
short_demo_data <- lapply(short_demo, function(x) x[sample(c(TRUE, NA),
                                                         prob = c(0.99999, 0.00001),size = length(x), replace = TRUE)])
# Reanme variables
levels(short_demo$SurveyType)[levels(short_demo$SurveyType)=="NatRep"] <- "Nationally rep."
# Reorder education factor
short_demo$Education <- factor(short_demo$Education_short, levels=c("Postgraduate degree",
         "Undergraduate degree","Further Education","Secondary school",
         "No formal qualifications", "Prefer not to answer", "Other"))
# Format table
table1::label(short_demo$Age_short) <- "Age group"
table1::label(short_demo$Area_type) <- "Area type"
table1::label(short_demo$Occupation_short) <- "Occupation"
table1::label(short_demo$Education_short) <- "Education"

# Create demo table
library(htmlTable)
library(kableExtra)
library(magick)

short_demo_table <- table1::table1(~Age_short + Gender + Education_short + Occupation_short + Area_type | SurveyType + SiteProximity, data = short_demo)
short_demo_table


```


```{r LONG demographics table, echo=FALSE, message=FALSE, warning=FALSE}
# Demographics table for publication


library("table1")
both_demo <- as.data.frame(all_demo)
both_demo_data <- lapply(both_demo, function(x) x[sample(c(TRUE, NA),
                                                         prob = c(0.99999, 0.00001),size = length(x), replace = TRUE)])
# Reanme variables
levels(both_demo$SurveyType)[levels(both_demo$SurveyType)=="NatRep"] <- "Nationally rep."
levels(both_demo$Education)[levels(both_demo$Education)=="Secondary school (GCSEs, A Levels or equivalent)"] <- "Secondary school"
levels(both_demo$Education)[levels(both_demo$Education)=="Postgraduate degree (Masters; Doctorate)"] <- "Postgraduate degree"
# Reorder education factor
both_demo$Education <- factor(both_demo$Education, levels=c("Postgraduate degree",
         "Undergraduate degree","Further Education","Secondary school",
         "No formal qualifications", "Prefer not to answer", "Other"))
# Format table
table1::label(both_demo$Age_group_match) <- "Age group"
table1::label(both_demo$Area_type) <- "Area type"
table1::label(both_demo$ReleaseSite) <- "Release site"
# Create demo table
library(htmlTable)
library(kableExtra)
library(magick)

full_demo_table <- table1::table1(~Age_group_match + Gender + Education + Occupation + Area_type | SurveyType + SiteProximity, data = both_demo)
full_demo_table


```



\newpage

### Respondent postcode mapping 

Maps of respondent location, seperating respondents according to survey type. The map indicates location using the first 4 digits of postcode (e.g., TN28), and points are colour-coded according to survey type.



```{r mapping postcodes polygon, include=FALSE}
# Download UK postcode polygon Shapefile
# download.file(
#   "http://www.opendoorlogistics.com/wp-content/uploads/Data/UK-postcode-boundaries-Jan-2015.zip",
#   "postal_shapefile"
# )
unzip("postal_shapefile")
# Read the downloaded Shapefile from disk
postal <- maptools::readShapeSpatial("./Distribution/Areas")
# Assign each "region" an unique id
postal.count <- nrow(postal@data)
postal@data$id <- 1:postal.count
# Transform SpatialPolygonsDataFrame to regular data.frame in ggplot format
postal.fort <- ggplot2::fortify(postal, region='id')
# Extract first two digits of postcode and make uppercase
all_demo$postal_area_code = toupper(substr(final_data$Postcode, 1, 2))
all_demo$postal_area_code <- gsub('[0-9]+', '', all_demo$postal_area_code)
df <- all_demo %>%
  dplyr::select(postal_area_code) %>% 
  group_by(postal_area_code) %>%
  summarise(freq = n())
# Add "region" id to frequency data
df <- merge(df, postal@data, by.x="postal_area_code", by.y="name")
# Merge frequency data onto geogrphical postal polygons
postal.fort <- merge(postal.fort,  df, by="id", all.x=T, all.y=F)
postal.fort <- postal.fort[order(postal.fort$order),] # Reordering since ggplot expect data.fram in same order as "order" column
postcode_2_map <- ggplot(postal.fort) + 
  geom_polygon(aes(x = long, y = lat, group = group, fill=freq), colour="#e6f7ff") + 
  scale_fill_gradient(low = "blue", high = "red") +
  labs(fill = "Respondent frequency", x = "Longitude", y = "Latitude") +
  coord_fixed()


```

```{r mapping postcodes points, include=FALSE}

### Alternative mapping method using first 4 digits (finer scale)
########################################
# Read the downloaded Shapefile from disk
postcode_outcodes <- read_csv("Distribution/postcode-outcodes.csv") # linking into a folder within working directory
head(postcode_outcodes)
# Extract first two four continuous digits of postcode and make uppercase
natrep_demo$postal_area_code = gsub( "\\s.*", "", natrep_data$Postcode)
natrep_demo$postal_area_code = toupper(substr(natrep_demo$postal_area_code, 1, 4))
#Your initial list is in Df_JVT with variable PostCodes.
natrep_list <- as.list(unique(natrep_demo$postal_area_code))
#Select your postcodes from Df_UK and choose variable to display on the map
natrep_datamap <- subset(postcode_outcodes, postcode_outcodes$postcode %in% natrep_list, select= c("postcode","latitude",  "longitude"))  
row.names(natrep_datamap) <- 1:nrow(natrep_datamap)
natrep_datamap$Survey <- "Nat.Representative"
# Extract first two four continuous digits of postcode and make uppercase
proact_demo$postal_area_code = gsub( "\\s.*", "", proact_data$Postcode)
proact_demo$postal_area_code = toupper(substr(proact_demo$postal_area_code, 1, 4))
#Your initial list is in Df_JVT with variable PostCodes.
proact_list <- as.list(unique(proact_demo$postal_area_code))
#Select your postcodes from Df_UK and choose variable to display on the map
proact_datamap <- subset(postcode_outcodes, postcode_outcodes$postcode %in% proact_list, select= c("postcode","latitude",  "longitude"))  
row.names(proact_datamap) <- 1:nrow(proact_datamap)
proact_datamap$Survey <- "Proactive"
#Combine map data
datamap <- rbind(natrep_datamap, proact_datamap)

###### Mapping reserve locations following https://www.r-spatial.org/r/2018/10/25/ggplot2-sf.html 
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
theme <- theme_set(theme())
theme_set(theme)

# Check coloublind palette
# display_carto_all(colorblind_friendly = TRUE)
# scales::show_col(safe_colorblind_palette)

# Plot reserves map (both surveys on one map)
postcode_4_map <- ggplot(data = world) +
  geom_sf(fill= "gray95") +
  coord_sf(xlim = c(-11, 3), ylim = c(49, 60), expand = FALSE) +
  geom_point(data = datamap, aes(x = longitude, y = latitude, colour=Survey), size = 1, shape = 19, alpha = 0.2)  +
  scale_colour_manual(values = c("#0072B2", "#D55E00")) + 
  ggspatial::annotation_scale(location = "bl", width_hint = 0.2) +
  labs(colour="Survey type", title="Respondent postcode map") + xlab("Longitude") + ylab("Latitude") +
  theme(panel.grid.major = element_line(color = gray(.5), linetype = "dashed", size = 0.5),
        panel.background = element_rect(fill = "#e6f7ff")) + facet_grid(~ Survey)
# both_postcode_4_map
ggsave("Ch4.both_reservesmap.png", width = 10, height = 6, dpi = 300)
```

```{r postcode map 2, fig.cap = "Map of first 4 digits of postcode (e.g., ), colour = survey type", fig.dim = c(10, 7), message=FALSE, echo=FALSE, warning=FALSE}

postcode_4_map
```


### Mapping proximity to WSP release sites 

Maps of each WSP release site and a 15km radius encompassing the 'local area' as referred to in the main manuscript. The following code creates an interactive map of each site on an Open Street Map base which can be explored like a Google map.

I have also created this map as an interactive Shiny object (hosted via Shiny.io in my personal account but this can be transferred over to a Project account later on). The map is accessible via this link: https://ljones42.shinyapps.io/WSP_site_map/ 

The code file for this is in the Shiny file called 'app.R', which can be updated, run and pushed to the server.

```{r Site OpenStreetMap, message=FALSE, warning=FALSE}

# Define data frame of site names and coordinates
marker_df <- read.csv(textConnection(
"Name,Lat,Long
Knepp,50.98341,-0.35485
Wadhurst,51.03579,0.32769
Wintershall,51.16605,-0.55289"))

## Create map iusing Leaflet
uk_map <- leaflet(marker_df) %>% 
  addTiles() %>%
  setView(lng=-0.35485, lat=50.98341, zoom = 9) %>%  # Set view to local area and zoom
  addMarkers(lng=~Long, lat=~Lat, popup = ~htmltools::htmlEscape(Name)) %>% 
  addCircles(lng=-0.35485, lat=50.98341, color = "red", radius = 15000) %>% 
  addCircles(lng=0.32769, lat=51.03579, color = "blue", radius = 15000) %>% 
  addCircles(lng=-0.55289, lat=51.16605, color = "green", radius = 15000) %>% 
  addMeasure() %>% # Add scale and ability to manually measure distance between points
  addMiniMap() # Add in a small minimap of wider area
uk_map

```



```{r mapping proxmity as circle, include=FALSE}

#### Alternative mapping option matching the participant location map

# 
# #### Create daaframe of coordinates
# data = data.frame(
#     ID = as.numeric(c(1:3)),
#     name = as.factor(c("Knepp", "Wadhurst", "Wintershall")),
#     latitude = as.numeric(c(50.98341, 51.03579, 51.16605)),
#     longitude = as.numeric(c(-0.35485, 0.32769, -0.55289))
# )
# # create circles data frame from the centers data frame
# make_circles <- function(centers, radius, nPoints = 100){
#     # centers: the data frame of centers with ID
#     # radius: radius measured in kilometer
#     #
#     meanLat <- mean(centers$latitude)
#     # length per longitude changes with lattitude, so need correction
#     radiusLon <- radius /15 / cos(meanLat/57.3) 
#     radiusLat <- radius / 15
#     circleDF <- data.frame(ID = rep(centers$ID, each = nPoints))
#     angle <- seq(0,2*pi,length.out = nPoints)
# 
#     circleDF$lon <- unlist(lapply(centers$longitude, function(x) x + radiusLon * cos(angle)))
#     circleDF$lat <- unlist(lapply(centers$latitude, function(x) x + radiusLat * sin(angle)))
#     return(circleDF)
# }
# # here is the data frame for all circles
# myCircles <- make_circles(data, 1.5)
# myCircles$Site <- recode_factor(as.factor(myCircles$ID),
#                       "1" = "Knepp", "2" = "Wadhurst", "3" = "Wintershall")
# # Plot reserves map (both surveys on one map)
# ggplot(data = GBR_sf) +
#   geom_sf(fill= "gray95") +
#   coord_sf(xlim = c(-1.5, 1.5), ylim = c(50.4, 51.75), expand = FALSE) +
#   geom_point(aes(x = longitude, y = latitude), data = data, color = "black")+
#   geom_polygon(data = myCircles, aes(lon, lat, group = Site, colour = as.factor(Site)), alpha = 0, size = 1.5) +
#   ggspatial::annotation_scale(location = "bl", width_hint = 0.2) +
#   labs(colour="Site") + 
#     xlab("Longitude") + ylab("Latitude") +
#   theme(panel.grid.major = element_line(color = gray(.5), linetype = "dashed", size = 0.2),
#         panel.background = element_rect(fill = "#e6f7ff"))
# 

```


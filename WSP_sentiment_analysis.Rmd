---
title: "WSP_R_Text_Analysis"
author: "Lizzie Jones"
date: "05/05/2021"
output: html_document
---

```{r setup/packages, messages = FALSE, include=FALSE}
# Assuming all packages are installed. If not use 'install.packages' e.g. install.packages("likert")
# Key packages for data wrangling
wrangling <- c("dplyr","tidyverse","purr","magrittr",
             "data.table","plyr","tidyr","tibble","reshape2")
lapply(wrangling, require, character.only = TRUE) 

# Useful survey analysis packages
survey <- c("likert","careless")
lapply(survey, require, character.only = TRUE) 

# Useful packages for statistics
stats <- c("stats","ggpubr","lme4","MASS","car","psych",
                   "MuMIn","glmmTMB","nlme","DHARMa")
lapply(stats, require, character.only = TRUE) 

# Useful packages for text analysis
text <- c("tm","koRpus","textstem", "tidytext","text2vec","lexicon","SentimentAnalysis","SnowballC",
          "qdap", "wordcloud", "sentimentr") # "textmineR","MediaNews","tau", "lsa","SemNeT","ngram","sylly","textir","ngramrr","corpustools","udpipe")
lapply(text, require, character.only = TRUE)

# Favourite data visualisation packages
vis <- c("ggvis","htmlwidgets","maps", "lattice","ggmap","ggplot2","plotly",
            "RColorBrewer", "sjPlot", "ggrepel")
lapply(vis, require, character.only = TRUE) 



# Load in working  directory and datasets
setwd("~/Documents/White-Stork-Project")

# Load in the data
original_data <- read.csv("Stork_MainDataset.csv", header = TRUE, stringsAsFactors=TRUE)
all_data <- read.csv("Stork_Dataset_Radapted.csv", header = TRUE, stringsAsFactors=TRUE)

# Two dataframes: one for each data collection (Proactive survey and Nationally representative survey) for easier comparison
proact_data <- all_data[which(all_data$SurveyType == "Proactive"),]
natrep_data <- all_data[which(all_data$SurveyType == "NatRep"),]

```

## R Markdown - WSP Text Analysis

#


```{r text cleaning, include = FALSE}

# Remind myself of the key open ended questions and their columns names
# Reasons for support/not support WSP
summary(all_data$Q15_WSP_support_open)
# View on management of WS
summary(all_data$Q16_views_management_open)
# Words used to describe WS - will probably combine into one column, labelled by Respondent ID and SurveyType
summary(all_data$Q11_word1)
summary(all_data$Q11_word2)
summary(all_data$Q11_word3)

# Create words df to seperately clean, capitalise first letter etc
words_df <- all_data %>%
  dplyr::select(UniqueID_short, SurveyType, Q11_word1, Q11_word2, Q11_word3) %>% 
  pivot_longer(
   cols = starts_with("Q11_"),
   names_to = "Word_num",
   values_to = "Words",
   values_drop_na = TRUE
 )

```

```{r create Corpus and wordcloud, messages=FALSE, warning=FALSE}

# Practicing using Q11 (words to describe WSP)
#Clean text
head(words_df)
words_df$Words <- gsub("[^[:graph:]]", " ", words_df$Words) #get rid of non graphical characters
words_df$Words <- gsub("rt", "", words_df$Words)# Replace blank space ("rt")
words_df$Words <- gsub("[[:punct:]]", "", words_df$Words)# Remove punctuation
words_df$Words <- gsub("[ |\t]{2,}", "", words_df$Words)# Remove tabs
words_df$Words <- gsub("^ ", "", words_df$Words)# Remove blank spaces at the beginning
words_df$Words <- gsub(" $", "", words_df$Words)# Remove blank spaces at the end
words_df$Words <- tolower(words_df$Words)#convert all text to lower case

Corpus_words <- Corpus(VectorSource(words_df$Words))
Corpus_words <- tm_map(Corpus_words, removeNumbers)
Corpus_words <- tm_map(Corpus_words, removeWords, stopwords("english")) #removes common english stopwords
# Corpus_words <- tm_map(Corpus_words, removeWords, c("muffin"))  #You can specify words to remove
# Corpus_words <- tm_map(Corpus_words, PlainTextDocument)

#build a term-document matrix
library("tm")
TDM_words = tm::TermDocumentMatrix(Corpus_words, control = list(minWordLength = 1))
m = as.matrix(TDM_words)
v = sort(rowSums(m), decreasing = TRUE)
d = data.frame(word = names(v),freq=v)

# Create a wordcloud
wordcloud(Corpus_words, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.25, 
          use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))

```

### Word frequency analysis (Words used to describe White Storks)

```{r Word frequency analysis, messages=FALSE, warning=FALSE}
# Frequent word analysis
# We can find the words that appear at least 100 times by calling the findFreqTerms() function on the term.doc.matrix
HiFreq_words <- findFreqTerms(TDM_words, 100)
HiFreq_words

# Now you also see how associated a word is to another word or a list of words.
findAssocs(TDM_words, HiFreq_words, 0.4)
# or, just compute word strength associations
findAssocs(TDM_words, "long", 0.5) # Looks like the word “long” and “legs” are very frequently associated (51% of the time)

barplot(d[1:15,]$freq, las = 2, names.arg = d[1:15,]$word,
        col ="lightblue", main ="Most frequent words used to describe White Storks",
        ylab = "Word frequencies")
```


### Sentiment analysis


```{r Sentiment analysis, messages=FALSE, warning=FALSE}
# Polarity / Sentiment Analysis

### Q8. How did you feel when you saw WS in the wild?
head(all_data$Q8.2_feelings)
# Clean the data
all_data$Q8.2_feelings_text <- gsub("[^[:graph:]]", " ", all_data$Q8.2_feelings) #get rid of non graphical characters
all_data$Q8.2_feelings_text <- gsub("^ ", "", all_data$Q8.2_feelings_text)# Remove blank spaces at the beginning
# Sentiment
class(all_data$Q8.2_feelings_text)
sentiment(get_sentences(all_data$Q8.2_feelings_text))





### Q15. Do you support the WSP?
head(all_data$Q15_WSP_support_open)
# Clean the data
all_data$Q15_WSP_support_text <- gsub("[^[:graph:]]", " ", all_data$Q15_WSP_support_open) #get rid of non graphical characters
all_data$Q15_WSP_support_text <- gsub("^ ", "", all_data$Q15_WSP_support_text)# Remove blank spaces at the beginning
all_data$Q15_WSP_support_text <- gsub(" $", "", all_data$Q15_WSP_support_text)# Remove blank spaces at the end

# Reasons for support/not support WSP
class(all_data$Q15_WSP_support_text)
sentiment(get_sentences(all_data$Q15_WSP_support_text))


# There are lots more ways of doing this (see the QDAP package vignette). Here we take a cleaned character vector used earlier (i.e. words_df$Words) and compare its sentiment against a grouping variable (e.g. SurveyType)
# poldat_surveytype <- with(all_data, polarity(words_df$Words, all_data$SurveyType))
# plot(poldat)



### Q16. What are yours views on the management of White Storks?
head(all_data$Q16_views_management_open)
# Clean the data
all_data$Q16_views_management_text <- gsub("[^[:graph:]]", " ", all_data$Q16_views_management_open) #get rid of non graphical characters
all_data$Q16_views_management_text <- gsub("^ ", "", all_data$Q16_views_management_text)# Remove blank spaces at the beginning
all_data$Q16_views_management_text <- gsub(" $", "", all_data$Q16_views_management_text)# Remove blank spaces at the end

# Reasons for support/not support WSP
class(all_data$Q16_views_management_text)
sentiment(get_sentences(all_data$Q16_views_management_text))




```
